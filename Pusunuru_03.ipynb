{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                Data Mining : Assignment 3\n",
    "\n",
    "##                                          Naive Bayes Classifier\n",
    "\n",
    "###                                                      Sameer Valiah Pusunuru\n",
    "###                                                              1001552473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "import nltk\n",
    "import operator\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from nltk.corpus import stopwords \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "geting file from the url path and then downloading it ,verfiying it and storing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOADED_FILENAME = 'data.tar.gz'\n",
    "\n",
    "def download_file(url_path):\n",
    "    if not os.path.exists(DOWNLOADED_FILENAME):\n",
    "        filename, _ = urllib.request.urlretrieve(url_path, DOWNLOADED_FILENAME)\n",
    "\n",
    "    print('Found and verified file from this path: ', url_path)\n",
    "    print('Downloaded file: ', DOWNLOADED_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after getting folder with data going into each folder and then storing data bases on postive negative reviews of train and test set also to remove the any charcater which is not alphabet or number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular expression to remove charcters other then alphabets or numbers\n",
    "TOKEN_REGEX = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "#function to clean each review\n",
    "def get_reviews(dirname, positive=True):\n",
    "    label = 1 if positive else 0\n",
    "\n",
    "    reviews = []\n",
    "    for filename in os.listdir(dirname):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(dirname + filename, 'r+', encoding=\"utf8\") as f:\n",
    "                review = f.read()\n",
    "                review = review.lower().replace(\"<br />\", \" \")\n",
    "                review = re.sub(TOKEN_REGEX, '', review)\n",
    "                reviews.append((review, label))\n",
    "    \n",
    "    return reviews \n",
    "#function to take one input at time and the clean the input using another function\n",
    "def extract_reviews():\n",
    "    if not os.path.exists('aclImdb'):\n",
    "        with tarfile.open(DOWNLOADED_FILENAME) as tar:\n",
    "            tar.extractall()\n",
    "            tar.close()   \n",
    "    positive_reviews = get_reviews(\"aclImdb/train/pos/\", positive=True)\n",
    "    positive_reviews_test = (get_reviews(\"aclImdb/test/pos/\", positive=True))\n",
    "    negative_reviews = get_reviews(\"aclImdb/train/neg/\", positive=False)\n",
    "    negative_reviews_test = get_reviews(\"aclImdb/test/neg/\", positive=False)\n",
    "    return positive_reviews, negative_reviews, positive_reviews_test, negative_reviews_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified file from this path:  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Downloaded file:  ImdbReviews.tar.gz\n"
     ]
    }
   ],
   "source": [
    "#web url for the folder\n",
    "URL_PATH = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "download_file(URL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stroing all the reviews \n",
    "positive_reviews, negative_reviews,positive_reviews_test,negative_reviews_test = extract_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_positive_reviews = positive_reviews_test+positive_reviews\n",
    "\n",
    "len(total_positive_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_negative_reviews =negative_reviews+negative_reviews_test\n",
    "\n",
    "len(total_negative_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diving the whole data in three parts DEV, TRAIN , TEst whith DEV and Train total to be 70% ~ 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = 17500\n",
    "train_reviews_positive = total_positive_reviews[:TRAIN_DATA] \n",
    "train_reviews_negative = total_negative_reviews[:TRAIN_DATA]\n",
    "test_reviews_postive = total_positive_reviews[TRAIN_DATA:]\n",
    "test_reviews_negative = total_negative_reviews[TRAIN_DATA:]\n",
    "total_test = test_reviews_postive+test_reviews_negative\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downloading stop woords and storing them so that we can remove them from our word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\samee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funtion to count number of words in the review and there number of accourances also removing the words which are repeated less then 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(train_reviews):\n",
    "    words_set = {}\n",
    "    for review in train_reviews:\n",
    "        for r in review[0].split():\n",
    "            if r in stop_words:\n",
    "                continue\n",
    "            else:\n",
    "                words_set[r] = words_set.get(r, 0) + 1\n",
    "    #removing word which are repeated less then 5 times\n",
    "    words_set_copy = {}           \n",
    "    for word in words_set:\n",
    "        val = words_set.get(word)\n",
    "        if(val>5):\n",
    "            words_set_copy[word] = val;\n",
    "    return words_set_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have to use k fold which is mentiones as 5 in the requirement ,I am diving my train and dev data into 5 parts with equal postive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#k fold :where k is 5 hence 5 sets of train data\n",
    "\n",
    "#set 1\n",
    "set1 = train_reviews_negative[:3500]+train_reviews_positive[:3500]\n",
    "set1train = train_reviews_negative[3500:]+ train_reviews_positive[3500:]\n",
    "\n",
    "#set2\n",
    "set2 = train_reviews_negative[3500:7000]+train_reviews_positive[3500:7000]\n",
    "set2train = train_reviews_negative[:3500]+train_reviews_negative[7000:]+ train_reviews_positive[:3500]+train_reviews_positive[7000:]\n",
    "\n",
    "#set3\n",
    "set3 = train_reviews_negative[7000:10500]+train_reviews_positive[7000:10500]\n",
    "set3train = train_reviews_negative[:7000]+train_reviews_negative[10500:]+ train_reviews_positive[:7000]+train_reviews_positive[10500:]\n",
    "\n",
    "#set4\n",
    "set4 = train_reviews_negative[10500:14000]+train_reviews_positive[10500:14000]\n",
    "set4train = train_reviews_negative[:10500]+train_reviews_negative[14000:]+ train_reviews_positive[:10500]+train_reviews_positive[14000:]\n",
    "\n",
    "#set5\n",
    "set5 = train_reviews_negative[14000:]+train_reviews_positive[14000:]\n",
    "set5train = train_reviews_negative[:14000]+train_reviews_positive[:14000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to find totalnumber of word in postive and negative reviews vocabulary without repetiton \n",
    "function to find the total number of postive/negative words count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total(negative,positive):\n",
    "    words_total = set()\n",
    "    \n",
    "    for review in negative:\n",
    "        for r in review[0].split():\n",
    "            words_total.add(r)\n",
    "    for review in positive:\n",
    "        for r in review[0].split():\n",
    "            words_total.add(r)\n",
    "        \n",
    "        \n",
    "    return(len(words_total))\n",
    "\n",
    "def totalWords(words):\n",
    "    count =0\n",
    "    for p in words:\n",
    "        count = count + words.get(p);\n",
    "        \n",
    "    return count\n",
    "def top10Words():\n",
    "    train_vocabulary_positive =get_vocabulary(train_reviews_positive)\n",
    "    train_vocabulary_negative =get_vocabulary(train_reviews_negative)\n",
    "    sorted_train_vocabulary_negative = sorted(train_vocabulary_negative.items(), key=operator.itemgetter(1),reverse = True)\n",
    "    sorted_train_vocabulary_positive = sorted(train_vocabulary_positive.items(), key=operator.itemgetter(1),reverse = True)\n",
    "    return sorted_train_vocabulary_negative,sorted_train_vocabulary_positive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions for finding probabilty using smoothing and without smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#the common probabilty finding by counts of words[i] in postive/negative divided by total postive/negative words count\n",
    "#where review is array of words\n",
    "def prob(setl,negativelen,positivelen,set1_vocabulary_negative,set1_vocabulary_positive):\n",
    "    count=0; \n",
    "    for review in setl:\n",
    "        val=0\n",
    "        for r in review[0].split():\n",
    "            pos=1\n",
    "            neg=1\n",
    "            if r in stop_words:\n",
    "                continue\n",
    "            else:\n",
    "                posval = set1_vocabulary_positive.get(r,0);\n",
    "                negval = set1_vocabulary_negative.get(r,0);\n",
    "                pos = (posval/positivelen)*pos\n",
    "                neg = (negval/negativelen)*neg\n",
    "        \n",
    "        if(pos>neg):\n",
    "            val=1;\n",
    "        if(val== review[1])  :  \n",
    "            count= count+1;\n",
    "    \n",
    "    return (count/len(setl))*100;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major problem with the basic probabilyt finding will be when a  word in review will not be found in postive vocabulary or negative vocabulary we get 0 which will make the whole probabilty 0, hence we require smoothing to make more effecient predications I am using Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this funtion we techincally do the same as the above but we add 1 to both \n",
    "def probSmooth(setl,wordlen,negativelen,positivelen,set1_vocabulary_negative,set1_vocabulary_positive):\n",
    "    count=0; \n",
    "    for review in setl:\n",
    "        val=0\n",
    "        pos=1\n",
    "        neg=1\n",
    "        for r in review[0].split():\n",
    "            \n",
    "            if r in stop_words:\n",
    "                continue\n",
    "            else:\n",
    "                posval = set1_vocabulary_positive.get(r,0)+1;\n",
    "                negval = set1_vocabulary_negative.get(r,0)+1;\n",
    "                pos = (posval/(positivelen+wordlen)+1)*pos\n",
    "                neg = (negval/(negativelen+wordlen)+1)*neg\n",
    "        \n",
    "        if(pos>neg):\n",
    "            val=1;\n",
    "        if(val== review[1])  :  \n",
    "            count= count+1;\n",
    "    \n",
    "    return (count/len(setl))*100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuract of 1st fold without smoothing 60.042857142857144\n",
      "Accuract of 1st fold with smoothing 66.0\n"
     ]
    }
   ],
   "source": [
    "#1 fold \n",
    "set1_vocabulary_negative =get_vocabulary(set1train[:14000])\n",
    "set1_vocabulary_positive =get_vocabulary(set1train[14000:])\n",
    "negativelen =totalWords(set1_vocabulary_negative)\n",
    "positivelen =totalWords(set1_vocabulary_positive)\n",
    "wordslen = total(set1train[:14000],set1train[14000:])\n",
    "\n",
    "\n",
    "accuracy1 = prob(set1,negativelen,positivelen,set1_vocabulary_negative,set1_vocabulary_positive) \n",
    "accuracy1_smooth = probSmooth(set1,wordslen,negativelen,positivelen,set1_vocabulary_negative,set1_vocabulary_positive) \n",
    "print(\"Accuract of 1st fold without smoothing \"+str(accuracy1))\n",
    "print(\"Accuract of 1st fold with smoothing \"+str(accuracy1_smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuract of 2nd fold without smoothing 58.72857142857143\n",
      "Accuract of 2nd fold with smoothing 66.52857142857142\n"
     ]
    }
   ],
   "source": [
    "#2 fold \n",
    "set2_vocabulary_negative =get_vocabulary(set2train[:14000])\n",
    "set2_vocabulary_positive =get_vocabulary(set2train[14000:])\n",
    "negativelen =totalWords(set2_vocabulary_negative)\n",
    "positivelen =totalWords(set2_vocabulary_positive)\n",
    "wordslen = total(set2train[:14000],set2train[14000:])\n",
    "accuracy2 = prob(set2,negativelen,positivelen,set2_vocabulary_negative,set2_vocabulary_positive) \n",
    "accuracy2_smooth = probSmooth(set2,wordslen,negativelen,positivelen,set2_vocabulary_negative,set2_vocabulary_positive)\n",
    "print(\"Accuract of 2nd fold without smoothing \"+str(accuracy2))\n",
    "print(\"Accuract of 2nd fold with smoothing \"+str(accuracy2_smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuract of 3rd fold without smoothing 60.08571428571429\n",
      "Accuract of 3rd fold with smoothing 64.97142857142858\n"
     ]
    }
   ],
   "source": [
    "#3 fold \n",
    "set3_vocabulary_negative =get_vocabulary(set3train[:14000])\n",
    "set3_vocabulary_positive =get_vocabulary(set3train[14000:])\n",
    "negativelen =totalWords(set3_vocabulary_negative)\n",
    "positivelen =totalWords(set3_vocabulary_positive)\n",
    "wordslen = total(set3train[:14000],set3train[14000:])\n",
    "accuracy3 = prob(set3,negativelen,positivelen,set3_vocabulary_negative,set3_vocabulary_positive) \n",
    "accuracy3_smooth = probSmooth(set3,wordslen,negativelen,positivelen,set3_vocabulary_negative,set3_vocabulary_positive)\n",
    "print(\"Accuract of 3rd fold without smoothing \"+str(accuracy3))\n",
    "print(\"Accuract of 3rd fold with smoothing \"+str(accuracy3_smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuract of 4th fold without smoothing 59.71428571428572\n",
      "Accuract of 4th fold with smoothing 65.8\n"
     ]
    }
   ],
   "source": [
    "#4 fold \n",
    "set4_vocabulary_negative =get_vocabulary(set4train[:14000])\n",
    "set4_vocabulary_positive =get_vocabulary(set4train[14000:])\n",
    "negativelen =totalWords(set4_vocabulary_negative)\n",
    "positivelen =totalWords(set4_vocabulary_positive)\n",
    "wordslen = total(set4train[:14000],set4train[14000:])\n",
    "accuracy4 = prob(set4,negativelen,positivelen,set4_vocabulary_negative,set4_vocabulary_positive)\n",
    "accuracy4_smooth = probSmooth(set4,wordslen,negativelen,positivelen,set4_vocabulary_negative,set4_vocabulary_positive)\n",
    "print(\"Accuract of 4th fold without smoothing \"+str(accuracy4))\n",
    "print(\"Accuract of 4th fold with smoothing \"+str(accuracy4_smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuract of 5th fold without smoothing 60.52857142857143\n",
      "Accuract of 5th fold with smoothing 66.62857142857142\n"
     ]
    }
   ],
   "source": [
    "#5 fold \n",
    "set5_vocabulary_negative =get_vocabulary(set5train[:14000])\n",
    "set5_vocabulary_positive =get_vocabulary(set5train[14000:])\n",
    "negativelen =totalWords(set5_vocabulary_negative)\n",
    "positivelen =totalWords(set5_vocabulary_positive)\n",
    "wordslen = total(set5train[:14000],set5train[14000:])\n",
    "accuracy5 = prob(set5,negativelen,positivelen,set5_vocabulary_negative,set5_vocabulary_positive) \n",
    "accuracy5_smooth = probSmooth(set5,wordslen,negativelen,positivelen,set5_vocabulary_negative,set5_vocabulary_positive)\n",
    "print(\"Accuract of 5th fold without smoothing \"+str(accuracy5))\n",
    "print(\"Accuract of 5th fold with smoothing \"+str(accuracy5_smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy without smoothing:-  59.894285714285715\n",
      "Average accuracy with smoothing:- 65.82000000000001\n"
     ]
    }
   ],
   "source": [
    "#Average of k fold comparing the smoothing and non smoothing \n",
    "accuracy_without_smooth = (accuracy1+accuracy2+accuracy3+accuracy3+accuracy5)/5;\n",
    "accuracy_smooth = (accuracy1_smooth+accuracy2_smooth+accuracy3_smooth+accuracy3_smooth+accuracy5_smooth)/5;\n",
    "print(\"Average accuracy without smoothing:-  \"+str(accuracy_without_smooth))\n",
    "print(\"Average accuracy with smoothing:- \"+str(accuracy_smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 word that predict positive and negative classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 in positive class \n",
      "\n",
      "movie\n",
      "film\n",
      "one\n",
      "like\n",
      "even\n",
      "bad\n",
      "good\n",
      "would\n",
      "really\n",
      "time\n",
      "\n",
      "Top 10 in negative class\n",
      "film\n",
      "movie\n",
      "one\n",
      "like\n",
      "good\n",
      "great\n",
      "story\n",
      "see\n",
      "time\n",
      "well\n"
     ]
    }
   ],
   "source": [
    "positive, negative =top10Words()\n",
    "print(\"Top 10 in positive class \\n\")\n",
    "for i in positive[:10]:\n",
    "    print(i[0])\n",
    "print(\"\\nTop 10 in negative class\")\n",
    "for i in negative[:10]:\n",
    "    print(i[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have found out that using smoothing gives us better prediction we use smoothing on out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy :- 65.44666666666666\n"
     ]
    }
   ],
   "source": [
    "train_vocabulary_negative =get_vocabulary(train_reviews_negative)\n",
    "train_vocabulary_positive =get_vocabulary(train_reviews_positive)\n",
    "negativelen =totalNegativeWords(train_vocabulary_negative)\n",
    "positivelen =totalPostiveWords(train_vocabulary_positive)\n",
    "wordslen = total(train_reviews_negative,train_reviews_positive)\n",
    "accuracy_test = probSmooth(total_test,wordslen,negativelen,positivelen,train_vocabulary_negative,train_vocabulary_positive)\n",
    "print(\"Final accuracy :- \"+ str(accuracy_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References :\n",
    "    \n",
    "https://stackoverflow.com/questions/7971618/python-return-first-n-keyvalue-pairs-from-dict\n",
    "https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "https://thispointer.com/python-how-to-add-append-key-value-pairs-in-dictionary-using-dict-update/\n",
    "https://towardsdatascience.com/unfolding-na%C3%AFve-bayes-from-scratch-2e86dcae4b01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
